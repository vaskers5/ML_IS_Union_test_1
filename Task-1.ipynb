{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "random.seed(0)#номер случайной последовательности, которую выдает генератор случайных чисел\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True#для воспроизводимости эксперимента\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"mushrooms.csv\", encoding='utf-8') as r_file:\n",
    "    # Создаем объект reader, указываем символ-разделитель \",\"\n",
    "    data = csv.reader(r_file, delimiter = \",\")\n",
    "    # Счетчик для подсчета количества строк и вывода заголовков столбцов\n",
    "df = pd.read_csv('mushrooms.csv',  # Это то, куда вы скачали файл\n",
    "                       sep=',')\n",
    "df['class'] = df['class'].replace({'e':1,'p':0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.array(df['class']) #labels\n",
    "for col in df.columns:\n",
    "    vals = df[col].apply(hash)\n",
    "df.head()\n",
    "\n",
    "dummies = pd.get_dummies(df)\n",
    "merged = pd.concat([df, dummies],axis = 'columns')\n",
    "cols = list(df.columns)\n",
    "cols.pop(0)\n",
    "final = merged.drop(cols,axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train = torch.tensor(df['class']).float() #labels\n",
    "Y_train = y_train[:7624]\n",
    "final = final.drop(['class'],axis = 'columns')\n",
    "X_train = final\n",
    "x_train = torch.tensor(X_train.values[:7624,1:])\n",
    "X_test =torch.tensor(X_train.values[7624:,1:])\n",
    "y_test = y_train[7624:]\n",
    "\n",
    "size = list(np.shape(x_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self,n_input, n_hidden_neurons):\n",
    "        super(Net,self).__init__()\n",
    "        #типикал структура сети,интересно почему 2 входа, но это еще прокомменчу\n",
    "        self.fc1 = torch.nn.Linear(n_input,n_hidden_neurons)#2 входа, ибо 2 колонки вина\n",
    "        self.activ1 = torch.nn.Sigmoid()\n",
    "        self.fc2 = torch.nn.Linear(n_hidden_neurons,n_hidden_neurons)\n",
    "        self.activ2 = torch.nn.Sigmoid()\n",
    "        self.fc3 = torch.nn.Linear(n_hidden_neurons,2)#3 возможных класса  => 3 возможных выхода\n",
    "        self.sm = torch.nn.Softmax(dim = 1)#софт-макс, принимающий на вход одномерный тензор\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.activ1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.activ2(x)\n",
    "        x = self.fc3(x)#хде софт-макс??\n",
    "        return x\n",
    "\n",
    "#выписываешь формулы кросс-энтропии и софт-макса и понимаешь что в одной экспа, в другой лог и все  уходит и софт-макс нахуй не нужен\n",
    "#для лосс-фукнции софт-макс нахуй не сдался, а вот для вероятностей пригодится    \n",
    "    def inference(self,x):#cчитаю вероятности выпадения определенного сорта говна\n",
    "        x = self.forward(x)\n",
    "        x = self.sm(x)\n",
    "        return x\n",
    "\n",
    "n_input = size[1]\n",
    "n_hidden = 30\n",
    "net = Net(n_input, n_hidden)\n",
    "#мы стараемся избегать софт-макса, ибо он весьма долгий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), \n",
    "                             lr=1.0e-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 0.992\n",
      "116 1.0\n",
      "116 1.0\n",
      "116 1.0\n",
      "116 1.0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "for epoch in range(50):\n",
    "    \n",
    "    order = np.random.permutation(len(x_train))\n",
    "   \n",
    "    for start_index in range(0, len(x_train), batch_size):\n",
    "    #каждую эпоху мешаю индексы и определяю в каком порядке буду их вытаскивать из сета\n",
    "        optimizer.zero_grad()#зануляю градиенты\n",
    "        batch_indexes = order[start_index:start_index+batch_size]\n",
    "    #каждую эпоху вырезаю куски из сета длинной в бач\n",
    "    \n",
    "        x_batch = x_train[batch_indexes]#вытаскиваю куски из сета\n",
    "        y_batch = y_train[batch_indexes]\n",
    "        preds = net.forward(x_batch.float())#сделаю небольшие предикты по бачам, по 3 выходам из сети\n",
    "    \n",
    "        loss_val = loss(preds, y_batch.long())#считаю лоссы по предиктам и лейблам\n",
    "    \n",
    "        loss_val.backward()#cчитаю производную по лоссу\n",
    "    \n",
    "        optimizer.step() # а теперь загоняю всю эту хуету в оптимайзер и делаю шаг гсп\n",
    "    #он как бы оборачивает собой все веса сети\n",
    "    \n",
    "    if epoch %10 == 0:\n",
    "        #каждые 100 эпох чекаем метрики для проверки тупости сети\n",
    "        test_preds = net.forward(X_test.float())\n",
    "       \n",
    "        test_preds = test_preds.argmax(dim = 1)#чекаем какой класс предсказывает сеть\n",
    "        #сравниваем номер нейрона в выходе и сравниваем его лейблом из теста\n",
    "        \n",
    "        print(net.fc1.in_features, np.asarray((test_preds == y_test).float().mean()))\n",
    "        #смотрим насколько сильно они совпадают\n",
    "        #тк мы не можем посчитать вероятность целочисленного, мы его приводим к дробному и считаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
